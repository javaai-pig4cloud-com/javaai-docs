---
title: "提示词"
---

提示是引导 AI 模型生成特定输出的输入。
提示的设计和措辞会显著影响模型的响应。

在 Spring AI 中与 AI 模型交互的最低层级，处理提示有点类似于在 Spring MVC 中管理"视图"。
这涉及创建带有动态内容占位符的大段文本。
这些占位符随后会根据用户请求或应用程序中的其他代码进行替换。
另一个类比是包含某些表达式占位符的 SQL 语句。

随着 Spring AI 的发展，它将引入更高级别的与 AI 模型交互的抽象。
本节描述的基础类在其角色和功能上可以类比为 JDBC。
例如，`ChatModel` 类类似于 JDK 中的核心 JDBC 库。
`ChatClient` 类类似于 `JdbcClient`，它构建在 `ChatModel` 之上，并通过 `Advisor` 提供更高级的构造，能够考虑与模型的历史交互、用额外的上下文文档增强提示，并引入代理行为。

提示的结构在 AI 领域内随着时间的推移而演变。
最初，提示只是简单的字符串。
随着时间的推移，它们发展为包含特定输入占位符，如"USER:"，AI 模型能够识别。
OpenAI 通过在处理前将多条消息字符串分类为不同角色，为提示引入了更多结构。

## API 概述

### Prompt

通常会使用 `ChatModel` 的 `call()` 方法，该方法接受一个 `Prompt` 实例并返回一个 `ChatResponse`。

`Prompt` 类作为有序 `Message` 对象序列和请求 `ChatOptions` 的容器。
每个 `Message` 在提示中都具有独特的角色，内容和意图各不相同。
这些角色可以包含多种元素，从用户提问到 AI 生成的响应，再到相关的背景信息。
这种安排使与 AI 模型的交互变得复杂且详细，因为提示由多个消息构建，每个消息在对话中扮演特定角色。

下面是 Prompt 类的简化版本，省略了构造函数和工具方法：

```java
public class Prompt implements ModelRequest<List<Message>> {

    private final List<Message> messages;

    private ChatOptions chatOptions;
}
```

### Message

`Message` 接口封装了提示的文本内容、元数据属性集合和称为 `MessageType` 的分类。

接口定义如下：

```java
public interface Content {

	String getContent();

	Map<String, Object> getMetadata();
}

public interface Message extends Content {

	MessageType getMessageType();
}
```

多模态消息类型还实现了 `MediaContent` 接口，提供 `Media` 内容对象列表。

```java
public interface MediaContent extends Content {

	Collection<Media> getMedia();

}
```

`Message` 接口有多种实现，对应于 AI 模型可以处理的不同类别的消息。
模型根据对话角色区分消息类别。

<Frame caption="Spring AI 消息 API">
  <img src="/images/spring-ai-message-api.jpg" width="800" />
</Frame>

这些角色由 `MessageType` 有效映射，如下所述。

#### 角色

每条消息都被分配了一个特定角色。
这些角色对消息进行分类，为 AI 模型澄清每个提示片段的上下文和目的。
这种结构化方法增强了与 AI 的交流的细致性和有效性，因为提示的每一部分在交互中都扮演着独特且明确定义的角色。

<CardGroup cols={2}>
  <Card title="系统角色" icon="cogs">
    指导 AI 的行为和响应风格，设置参数或规则，规定 AI 如何解释和回复输入。类似于在开始对话前为 AI 提供指令。
  </Card>
  <Card title="用户角色" icon="user">
    代表用户的输入——他们对 AI 的问题、命令或陈述。这个角色是基础，因为它构成了 AI 响应的依据。
  </Card>
  <Card title="助手角色" icon="robot">
    AI 对用户输入的响应。不仅仅是答案或反应，对于维持对话的流畅性至关重要。
    通过跟踪 AI 先前的响应（其"助手角色"消息），系统确保交互的连贯性和上下文相关性。
    助手消息还可能包含函数工具调用请求信息。
    这就像 AI 的一个特殊功能，在需要时用于执行特定功能，如计算、获取数据或其他超出对话的任务。
  </Card>
  <Card title="工具/函数角色" icon="tools">
    工具/函数角色专注于响应工具调用助手消息时返回额外信息。
  </Card>
</CardGroup>

角色在 Spring AI 中以枚举方式表示，如下所示：

```java
public enum MessageType {

	USER("user"),

	ASSISTANT("assistant"),

	SYSTEM("system"),

	TOOL("tool");

    ...
}
```

### PromptTemplate

Spring AI 中提示模板的关键组件是 `PromptTemplate` 类，旨在便于创建结构化提示，然后将其发送给 AI 模型进行处理。

```java
public class PromptTemplate implements PromptTemplateActions, PromptTemplateMessageActions {

    // 其他方法后续讨论
}
```

该类使用 `TemplateRenderer` API 渲染模板。默认情况下，Spring AI 使用基于 Terence Parr 开发的开源 [StringTemplate](https://www.stringtemplate.org/) 引擎的 `StTemplateRenderer` 实现。模板变量由 `{}` 语法标识，但您也可以配置分隔符以使用其他语法。

```java
public interface TemplateRenderer extends BiFunction<String, Map<String, Object>, String> {

	@Override
	String apply(String template, Map<String, Object> variables);

}
```

Spring AI 使用 `TemplateRenderer` 接口处理变量到模板字符串的实际替换。
默认实现使用 StringTemplate。
如果需要自定义逻辑，您可以提供自己的 `TemplateRenderer` 实现。
对于不需要模板渲染的场景（例如模板字符串已完整），可以使用提供的 `NoOpTemplateRenderer`。

<CodeGroup>
  <code title="自定义 StringTemplate 渲染器">
```java
PromptTemplate promptTemplate = PromptTemplate.builder()
    .renderer(StTemplateRenderer.builder().startDelimiterToken('<').endDelimiterToken('>').build())
    .template("""
            告诉我 5 部由 <composer> 作曲的电影名称。
            """)
    .build();

String prompt = promptTemplate.render(Map.of("composer", "John Williams"));
```
  </code>
</CodeGroup>

该类实现的接口支持提示创建的不同方面：

- `PromptTemplateStringActions` 专注于创建和渲染提示字符串，代表最基本的提示生成形式。
- `PromptTemplateMessageActions` 针对通过生成和操作 `Message` 对象进行提示创建。
- `PromptTemplateActions` 旨在返回 `Prompt` 对象，可传递给 `ChatModel` 以生成响应。

虽然这些接口在许多项目中可能不会被广泛使用，但它们展示了提示创建的不同方法。

实现的接口如下：

```java
public interface PromptTemplateStringActions {

	String render();

	String render(Map<String, Object> model);

}
```

<Accordion title="PromptTemplateStringActions 方法">
  - `String render()`：将提示模板渲染为最终字符串格式，无需外部输入，适用于无占位符或动态内容的模板。
  - `String render(Map<String, Object> model)`：增强渲染功能以包含动态内容。它使用 `Map<String, Object>`，其中 map 的键是提示模板中的占位符名称，值是要插入的动态内容。
</Accordion>

```java
public interface PromptTemplateMessageActions {

	Message createMessage();

    Message createMessage(List<Media> mediaList);

	Message createMessage(Map<String, Object> model);

}
```

<Accordion title="PromptTemplateMessageActions 方法">
  - `Message createMessage()`：创建不带附加数据的 `Message` 对象，用于静态或预定义的消息内容。
  - `Message createMessage(List<Media> mediaList)`：创建带有静态文本和媒体内容的 `Message` 对象。
  - `Message createMessage(Map<String, Object> model)`：扩展消息创建以集成动态内容，接受 `Map<String, Object>`，每个条目代表消息模板中的占位符及其对应的动态值。
</Accordion>

```java
public interface PromptTemplateActions extends PromptTemplateStringActions {

	Prompt create();

	Prompt create(ChatOptions modelOptions);

	Prompt create(Map<String, Object> model);

	Prompt create(Map<String, Object> model, ChatOptions modelOptions);

}
```

<Accordion title="PromptTemplateActions 方法">
  - `Prompt create()`：生成不带外部数据输入的 `Prompt` 对象，适用于静态或预定义的提示。
  - `Prompt create(ChatOptions modelOptions)`：生成不带外部数据输入且带有特定聊天请求选项的 `Prompt` 对象。
  - `Prompt create(Map<String, Object> model)`：扩展提示创建能力以包含动态内容，接受 `Map<String, Object>`，每个 map 条目是提示模板中的占位符及其关联的动态值。
  - `Prompt create(Map<String, Object> model, ChatOptions modelOptions)`：扩展提示创建能力以包含动态内容，接受 `Map<String, Object>`，每个 map 条目是提示模板中的占位符及其关联的动态值，并带有特定的聊天请求选项。
</Accordion>

## 示例用法

以下是 [AI Workshop on PromptTemplates](https://github.com/Azure-Samples/spring-ai-azure-workshop/blob/main/2-README-prompt-templating.md) 中的一个简单示例。

```java
PromptTemplate promptTemplate = new PromptTemplate("Tell me a {adjective} joke about {topic}");

Prompt prompt = promptTemplate.create(Map.of("adjective", adjective, "topic", topic));

return chatModel.call(prompt).getResult();
```

另一个示例来自 [AI Workshop on Roles](https://github.com/Azure-Samples/spring-ai-azure-workshop/blob/main/3-README-prompt-roles.md)：

```java
String userText = """
    告诉我三位黄金时代著名海盗以及他们为什么出名。
    每位海盗至少写一句话。
    """;
```

## 提示工程

在生成 AI 中，提示的创建是开发人员的重要任务。
提示的质量和结构会显著影响 AI 的输出效果。
在设计提示上投入时间和精力可以大大提高 AI 的结果。

分享和讨论提示是 AI 社区中的常见做法。
这种协作方法不仅创造了共享学习环境，还导致了高度有效提示的识别和使用。

该领域的研究通常涉及分析和比较不同的提示，以评估它们在各种情况下的有效性。
例如，一项重大研究证明，从"Take a deep breath and work on this problem step by step"开始，问题解决效率显著提高。
这强调了语言选择对生成 AI 系统性能的影响。

掌握提示的最佳使用，特别是在 AI 技术快速发展的情况下，是一个持续的挑战。
你应该认识到提示工程的重要性，并考虑使用社区和研究中的见解来改进提示创建策略。

### 创建有效提示

在开发提示时，重要的是整合几个关键组件，以确保清晰和有效性：

<AccordionGroup>
  <Accordion title="Instructions" icon="book">
    Offer clear and direct instructions to the AI, similar to how you would communicate with a person. This clarity is essential for helping the AI "understand" what is expected.
  </Accordion>
  
  <Accordion title="External Context" icon="globe">
    Include relevant background information or specific guidance for the AI's response when necessary. This "external context" frames the prompt and aids the AI in grasping the overall scenario.
  </Accordion>
  
  <Accordion title="User Input" icon="keyboard">
    This is the straightforward part - the user's direct request or question forming the core of the prompt.
  </Accordion>
  
  <Accordion title="Output Indicator" icon="arrow-right">
    This aspect can be tricky. It involves specifying the desired format for the AI's response, such as JSON. However, be aware that the AI might not always adhere strictly to this format. For instance, it might prepend a phrase like "here is your JSON" before the actual JSON data, or sometimes generate a JSON-like structure that is not accurate.
  </Accordion>
</AccordionGroup>

提供 AI 预期的提问和答案格式示例可以极大地帮助在创建提示时。
这种做法帮助 AI "理解"查询的结构和意图，导致更精确和相关的响应。
虽然此文档不会深入探讨这些技术，但它们为 AI 提示工程提供了起点。

以下是进一步调查的资源列表。

#### Simple Techniques

<CardGroup cols={2}>
  <Card title="Text Summarization" icon="file-alt" href="https://www.promptingguide.ai/introduction/examples.en#text-summarization">
    Reduces extensive text into concise summaries, capturing key points and main ideas while omitting less critical details.
  </Card>
  
  <Card title="Question Answering" icon="question-circle" href="https://www.promptingguide.ai/introduction/examples.en#question-answering">
    Focuses on deriving specific answers from provided text, based on user-posed questions. It's about pinpointing and extracting relevant information in response to queries.
  </Card>
  
  <Card title="Text Classification" icon="tags" href="https://www.promptingguide.ai/introduction/examples.en#text-classification">
    Systematically categorizes text into predefined categories or groups, analyzing the text and assigning it to the most fitting category based on its content.
  </Card>
  
  <Card title="Conversation" icon="comments" href="https://www.promptingguide.ai/introduction/examples.en#conversation">
    Creates interactive dialogues where the AI can engage in back-and-forth communication with users, simulating a natural conversation flow.
  </Card>
  
  <Card title="Code Generation" icon="code" href="https://www.promptingguide.ai/introduction/examples.en#code-generation">
    Generates functional code snippets based on specific user requirements or descriptions, translating natural language instructions into executable code.
  </Card>
</CardGroup>

#### Advanced Techniques

<CardGroup cols={3}>
  <Card title="Zero-shot, Few-shot Learning" icon="bolt" href="https://www.promptingguide.ai/techniques/zeroshot">
    Enables the model to make accurate predictions or responses with minimal to no prior examples of the specific problem type, understanding and acting on new tasks using learned generalizations.
  </Card>
  
  <Card title="Chain-of-Thought" icon="link" href="https://www.promptingguide.ai/techniques/cot">
    Links multiple AI responses to create a coherent and contextually aware conversation. It helps the AI maintain the thread of the discussion, ensuring relevance and continuity.
  </Card>
  
  <Card title="ReAct (Reason + Act)" icon="brain" href="https://www.promptingguide.ai/techniques/react">
    In this method, the AI first analyzes (reasons about) the input, then determines the most appropriate course of action or response. It combines understanding with decision-making.
  </Card>
</CardGroup>

#### Microsoft Guidance

<Card title="Framework for Prompt Creation and Optimization" icon="microsoft" href="https://github.com/microsoft/guidance">
  Microsoft offers a structured approach to developing and refining prompts. This framework guides users in creating effective prompts that elicit the desired responses from AI models, optimizing the interaction for clarity and efficiency.
</Card>

## Tokens

Tokens 在 AI 模型处理文本中起着关键作用，它们充当中介，将我们理解的单词转换为 AI 模型可以处理的格式。
这种转换发生在两个阶段：单词在输入时转换为 tokens，然后这些 tokens 再转换回单词输出。

Tokenization，将文本分解为 tokens 的过程，是 AI 模型理解和处理语言的基础。
AI 模型使用这种 tokenized 格式来理解和响应提示。

为了更好地理解 tokens，可以将其视为单词的一部分。通常，一个 token 代表大约三个四分之一单词。例如，莎士比亚的完整作品，总计约 900,000 个单词，将翻译为约 120 万个 tokens。

实验使用 [OpenAI Tokenizer UI](https://platform.openai.com/tokenizer) 查看单词如何转换为 tokens。

Tokens 在 AI 处理中的实际含义超出了它们的技术角色，特别是在与计费和模型能力相关：

<AccordionGroup>
  <Accordion title="Billing" icon="dollar-sign">
    AI 模型服务通常根据 token 使用量计费。输入（提示）和输出（响应）都贡献到总 token 计数中，使较短的提示更经济。
  </Accordion>
  
  <Accordion title="Model Limits" icon="barrier-block">
    Different AI 模型具有不同的 token 限制，定义它们的 "context window" ——它们一次可以处理的最大信息量。例如，GPT-3 限制为 4K tokens，而其他模型如 Claude 2 和 Meta Llama 2 限制为 100K tokens，一些研究模型可以处理高达 100 万个 tokens。
  </Accordion>
  
  <Accordion title="Context Window" icon="window">
    A model's token limit determines its context window。如果输入超过此限制，模型不会处理输入。为了处理，只需发送最小有效信息集。例如，在询问 "Hamlet" 时，没有必要包括莎士比亚其他作品的 tokens。
  </Accordion>
  
  <Accordion title="Response Metadata" icon="info-circle">
    来自 AI 模型的响应的元数据包括使用的 token 数量，对于管理使用和成本至关重要。
  </Accordion>
</AccordionGroup> 